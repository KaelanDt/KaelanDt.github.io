<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Publications</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <nav>
            <ul>
                <li><a href="index.html">Home</a></li>
                <li><a href="publications.html">Publications</a></li>
            </ul>
        </nav>
    </header>
    <main>
     Most of my early work has revolved around numerical methods for scientific computing, for which libraries and packages are very useful. For my first research projects I used <a href="https://github.com/JuliaLang/julia">julia</a>, which gave me a taste for functional programming, and I was an avid user of <a href="https://github.com/qojulia/QuantumOptics.jl">QuantumOptics.jl</a> for some time.
     Then I started machine learning, and for this I first used <a href="https://github.com/FluxML/Flux.jl">Flux.jl</a>, which is great but lacks a lot of support for modern tools. 
     I therefore went over to Python, and used <a href="https://github.com/netket/netket">netket</a>, a great <a href="https://github.com/google/jax">jax</a>-based livrary spearheaded by a F. Vicentini, a former labmate.
    After that at Normal I worked on a few nice libraries for thermodynamic computing and more recently I worked on <a href="https://github.com/lightning-ai/lightning-thunder">Thunder</a>, Lightning's PyTorch compiler.
     <h2>Open-source contributions</h2>
        <h3>2025</h3>
        <ul>
            <li><strong> <a href="https://github.com/lightning-ai/lightning-thunder">Thunder</a> </strong><br>
                <i> Thomas Viehmann et al. </i><br>
                Thunder is a PyTorch compiler that aims to simplify the model optimization workflow. If you've ever tried to optimize a model in PyTorch, you generally start by trying to use `torch.compile`, and that slowly becomes tweaking knobs for things you don't necessarily understand if you're not an expert. In Thunder the great Thomas Viehmann wrote an interpreter in Python, meaning that all traces are python code and very easily inspectable. You also get to see how the traces are modified step-by-step based on the optimizations applied.
            </li>     
        </ul>
        <h3>2024</h3>
        <ul>
            <li><strong> <a href="https://github.com/normal-computing/posteriors">posteriors</a> </strong><br>
                <i> S. Duffield, Me, and J. Chiu, P. Klett and D. Simpson</i><br>
                posteriors is the *go-to library* for uncertainty quantification of LLMs. It is functional, swappable, transformers-compatible and contains the basic important UQ methods, such as Laplace approximations, Monte-Carlo methods and variational inference. I also contributed an efficient conjugate gradient solver using fisher-vector products in pytorch, which doesn't seem to exist anywhere.
                Check out the <a href="https://www.normalcomputing.com/blog-posts/posteriors-normal-computings-library-for-uncertainty-aware-llms-3">blog post</a>
            </li>     
            <li><strong> <a href="https://github.com/normal-computing/thermox">thermox</a> </strong><br>
                <i> S. Duffield & Me</i><br>
            thermox is the *best OU process simulator*, as it is exact, GPU-compatible and uses associative scans. This is used internally by us for simulation thermodynamic hardware, but can be useful for many other things (finance people contributions welcome!).
             Check out the <a href="https://www.normalcomputing.com/blog-posts/thermox-the-first-thermodynamic-computing-simulator">blog post</a>
            </li>
        </ul>
        
        
    </main>
    <footer>
        <p>&copy; 2024 Kaelan Donatella</p>
    </footer>
</body>
</html>
